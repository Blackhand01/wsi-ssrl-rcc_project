{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118033,
     "status": "ok",
     "timestamp": 1749305392367,
     "user": {
      "displayName": "Stefano Bisignano",
      "userId": "12037847569875379268"
     },
     "user_tz": -120
    },
    "id": "8cOZCcsp0RCa",
    "outputId": "e1bb265d-82c7-45dc-a114-5cf52d792200"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=False)\n",
    "\n",
    "!pip install --quiet torch torchvision webdataset tqdm pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13301,
     "status": "ok",
     "timestamp": 1749305405756,
     "user": {
      "displayName": "Stefano Bisignano",
      "userId": "12037847569875379268"
     },
     "user_tz": -120
    },
    "id": "CPkMc3ONzi0J",
    "outputId": "b0dee59a-0134-494c-e50a-e2e92b126243"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 PROJECT_ROOT: /content/drive/MyDrive/ColabNotebooks/wsi-ssrl-rcc_project\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "import logging\n",
    "import torch\n",
    "from typing import Any, Dict\n",
    "from tqdm import tqdm\n",
    "import inspect\n",
    "\n",
    "config_path = Path('/content/drive/MyDrive/Colab Notebooks/MLA_PROJECT/wsi-ssrl-rcc_project/config/training.yaml')\n",
    "\n",
    "with config_path.open('r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "colab_root = Path(cfg['env_paths']['colab'])\n",
    "local_root = Path(cfg['env_paths']['local'])\n",
    "PROJECT_ROOT = colab_root if colab_root.exists() else local_root\n",
    "if not PROJECT_ROOT.exists():\n",
    "    raise FileNotFoundError(f\"Project root not find: {PROJECT_ROOT}\")\n",
    "\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
    "\n",
    "\n",
    "from importlib.util import spec_from_file_location, module_from_spec\n",
    "\n",
    "utils_dir = PROJECT_ROOT / 'src' / 'utils'\n",
    "src_file = utils_dir / 'training_utils.py'\n",
    "\n",
    "spec = spec_from_file_location('utils.training_utils', str(src_file))\n",
    "training_utils = module_from_spec(spec)\n",
    "spec.loader.exec_module(training_utils)\n",
    "\n",
    "sys.modules['utils.training_utils'] = training_utils\n",
    "\n",
    "from utils.training_utils import TRAINER_REGISTRY\n",
    "from trainers.extract_features import extract_features\n",
    "from trainers.train_classifier import train_classifier\n",
    "from utils.training_utils import get_latest_checkpoint, load_checkpoint\n",
    "print(f\"🔥 PROJECT_ROOT: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1749210491818,
     "user": {
      "displayName": "Stefano Bisignano",
      "userId": "12037847569875379268"
     },
     "user_tz": -120
    },
    "id": "lIancWXKKuOY",
    "outputId": "bec2e845-d808-445d-f65a-ad46274e2f06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Dataset paths:\n",
      "  • train: /content/drive/MyDrive/ColabNotebooks/wsi-ssrl-rcc_project/data/processed/webdataset_2500/train/patches-0000.tar\n",
      "  • val: /content/drive/MyDrive/ColabNotebooks/wsi-ssrl-rcc_project/data/processed/webdataset_2500/val/patches-0000.tar\n",
      "  • test: /content/drive/MyDrive/ColabNotebooks/wsi-ssrl-rcc_project/data/processed/webdataset_2500/test/patches-0000.tar\n"
     ]
    }
   ],
   "source": [
    "for split in ['train','val','test']:\n",
    "    rel = cfg['data'].get(split)\n",
    "    if rel:\n",
    "        cfg['data'][split] = str(PROJECT_ROOT / rel)\n",
    "\n",
    "print(\"📂 Dataset paths:\")\n",
    "for split in ['train','val','test']:\n",
    "    print(f\"  • {split}: {cfg['data'][split]}\")\n",
    "\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "sys.path.insert(0, str(PROJECT_ROOT / 'src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UIj4XOZP6U9"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)-8s | %(name)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(\"LAUNCHER\")\n",
    "logger.info(\"✅ Logger initialized at INFO level\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwx0_Pr9E59j"
   },
   "outputs": [],
   "source": [
    "trainer_modules = [\n",
    "    \"trainers.simclr\",\n",
    "    \"trainers.moco_v2\",\n",
    "    \"trainers.rotation\",\n",
    "    \"trainers.jigsaw\",\n",
    "    \"trainers.supervised\",\n",
    "    \"trainers.transfer\",\n",
    "]\n",
    "for module_name in trainer_modules:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "    else:\n",
    "        importlib.import_module(module_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMV3BYIyE7FM"
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import time\n",
    "\n",
    "def launch_training(cfg: dict) -> None:\n",
    "    models_cfg = cfg.get('models', {})\n",
    "    run_model = cfg.get('run_model', 'all').lower()\n",
    "    if run_model == 'all':\n",
    "        tasks = list(models_cfg.items())\n",
    "    else:\n",
    "        if run_model not in models_cfg:\n",
    "            raise KeyError(f\"Model '{run_model}' not found in cfg['models']\")\n",
    "        tasks = [(run_model, models_cfg[run_model])]\n",
    "\n",
    "    for name, m_cfg in tasks:\n",
    "        if name not in TRAINER_REGISTRY:\n",
    "            raise KeyError(f\"No trainer registered for '{name}'\")\n",
    "\n",
    "        trainer = TRAINER_REGISTRY[name](m_cfg, cfg['data'])\n",
    "        device = getattr(trainer, 'device', 'n/a')\n",
    "        epochs = int(m_cfg['training'].get('epochs', 0))\n",
    "        batch_size = int(m_cfg['training'].get('batch_size', 0))\n",
    "\n",
    "        print(f\"Device: {device} 🚀  Starting training for model '{name}'\")\n",
    "        print(f\"→ Model config: {m_cfg}\")\n",
    "        print(f\"Epochs: {epochs} | Batch size: {batch_size}\\n\")\n",
    "\n",
    "        has_validation = hasattr(trainer, 'validate_epoch')\n",
    "        train_dir = Path(cfg['data']['train']).parent\n",
    "        ckpt_dir = train_dir / \"checkpoints\"\n",
    "        ckpt_path = ckpt_dir / f\"{trainer.__class__.__name__}_best.pt\"\n",
    "\n",
    "        skip_training = False\n",
    "        if ckpt_path.exists():\n",
    "            print(f\"⏭️  Checkpoint already found for '{name}' → skip training and load encoder.\")\n",
    "            model = torch.nn.Sequential(trainer.encoder, trainer.projector)\n",
    "            load_checkpoint(ckpt_path, model=model)\n",
    "            trainer.encoder = model[0].to(trainer.device)\n",
    "            skip_training = True\n",
    "\n",
    "        if not skip_training:\n",
    "            for epoch in range(1, epochs + 1):\n",
    "                epoch_start = time.time()\n",
    "                total_batches = getattr(trainer, 'batches_train', None)\n",
    "                print(f\"TOTAL BATCHES {total_batches}\")\n",
    "                running_loss, running_correct, total_samples = 0.0, 0, 0\n",
    "\n",
    "                print(f\"--- Epoch {epoch}/{epochs} ---\")\n",
    "                for i, batch in enumerate(trainer.train_loader, start=1):\n",
    "                    sig = inspect.signature(trainer.train_step)\n",
    "                    result = trainer.train_step(batch) if len(sig.parameters) == 1 else trainer.train_step(*batch)\n",
    "                    if len(result) == 4:\n",
    "                        _, loss, correct, bs = result\n",
    "                    else:\n",
    "                        loss, bs = result\n",
    "                        correct = 0\n",
    "\n",
    "                    running_loss += loss * bs\n",
    "                    running_correct += correct\n",
    "                    total_samples += bs\n",
    "                    avg_loss = running_loss / total_samples\n",
    "                    avg_acc = (running_correct / total_samples) if has_validation else 0.0\n",
    "                    elapsed = time.time() - epoch_start\n",
    "                    pct = (i / total_batches) * 100 if total_batches else 0.0\n",
    "                    eta = (elapsed / i) * (total_batches - i) if total_batches else 0.0\n",
    "\n",
    "                    msg = f\"  Batch {i}/{total_batches} ({pct:.1f}%) | Loss: {avg_loss:.4f}\"\n",
    "                    if has_validation:\n",
    "                        msg += f\" | Acc: {avg_acc:.3f}\"\n",
    "                    msg += f\" | Elapsed: {elapsed:.1f}s | ETA: {eta:.1f}s\"\n",
    "                    print(msg)\n",
    "\n",
    "                if has_validation:\n",
    "                    val_loss, val_acc = trainer.validate_epoch()\n",
    "                    print(f\"Val -> Loss: {val_loss:.4f} | Acc: {val_acc:.3f}\")\n",
    "                    trainer.post_epoch(epoch, val_acc)\n",
    "                else:\n",
    "                    epoch_loss = running_loss / total_samples\n",
    "                    trainer.post_epoch(epoch, epoch_loss)\n",
    "\n",
    "                print(f\"Epoch {epoch} completed in {time.time() - epoch_start:.1f}s\\n\")\n",
    "\n",
    "        best = trainer.summary()\n",
    "        if isinstance(best, tuple) and len(best) == 2:\n",
    "            be, bm = best\n",
    "            print(f\"✅ Training for '{name}' completed. Best @ epoch {be} -> {bm:.3f}\")\n",
    "\n",
    "        # Only for self-supervised\n",
    "        if not has_validation:\n",
    "            print(f\"🔍 Extracting features from model '{name}'\")\n",
    "            feature_path = PROJECT_ROOT / f\"features/{name}_features.pt\"\n",
    "            feature_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            if hasattr(trainer, \"extract_features_to\"):\n",
    "                trainer.extract_features_to(str(feature_path))\n",
    "                print(f\"✅ Features saved to {feature_path}\")\n",
    "            else:\n",
    "                print(f\"⚠️ Trainer '{name}' does not implement extract_features_to(), skipping.\")\n",
    "\n",
    "            print(f\"🧠 Training classifier on features '{name}'\")\n",
    "            train_classifier(\n",
    "                features_path=str(feature_path),\n",
    "                output_model=str(PROJECT_ROOT / f\"classifier/{name}_classifier.joblib\")\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 919846,
     "status": "ok",
     "timestamp": 1749211459903,
     "user": {
      "displayName": "Stefano Bisignano",
      "userId": "12037847569875379268"
     },
     "user_tz": -120
    },
    "id": "xFDhQTgUOwYJ",
    "outputId": "f7f1a9de-9a19-4d55-b0ba-4ffb5c0ccaa0"
   },
   "outputs": [],
   "source": [
    "launch_training(cfg)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNMUn+/uyACrBWAZGivnsuX",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
