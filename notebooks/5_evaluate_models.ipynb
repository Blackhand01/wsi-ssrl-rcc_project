{"cells":[{"cell_type":"code","execution_count":1,"id":"848a37f5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"848a37f5","executionInfo":{"status":"ok","timestamp":1750513778167,"user_tz":-120,"elapsed":11127,"user":{"displayName":"Mirko Di Maggio","userId":"13413056271228513717"}},"outputId":"10f8b3c2-9565-45fc-b42a-948538e5a216"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","\n","!pip install --quiet torch torchvision webdataset tqdm pillow scikit-learn joblib\n"]},{"cell_type":"code","execution_count":2,"id":"262cef02","metadata":{"id":"262cef02","executionInfo":{"status":"ok","timestamp":1750513781644,"user_tz":-120,"elapsed":3473,"user":{"displayName":"Mirko Di Maggio","userId":"13413056271228513717"}}},"outputs":[],"source":["from pathlib import Path\n","import sys, yaml, torch, importlib, logging, joblib\n","from collections import defaultdict, Counter\n","from tqdm import tqdm\n","import numpy as np\n","\n","# üìÅ Configurazione percorso progetto\n","config_path = Path('/content/drive/MyDrive/Colab Notebooks/MLA_PROJECT/wsi-ssrl-rcc_project/config/training.yaml')\n","with config_path.open('r') as f:\n","    cfg = yaml.safe_load(f)\n","\n","colab_root = Path(cfg['env_paths']['colab'])\n","local_root = Path(cfg['env_paths']['local'])\n","PROJECT_ROOT = colab_root if colab_root.exists() else local_root\n","\n","sys.path.insert(0, str(PROJECT_ROOT))\n","sys.path.insert(0, str(PROJECT_ROOT / \"src\"))\n","\n","# Normalizza i path dei dati\n","for split in ['train','val','test']:\n","    rel = cfg['data'].get(split)\n","    if rel:\n","        cfg['data'][split] = str(PROJECT_ROOT / rel)\n","\n","# Setup logging\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger(\"EVAL\")\n"]},{"cell_type":"code","execution_count":3,"id":"309c640e","metadata":{"id":"309c640e","executionInfo":{"status":"ok","timestamp":1750513785617,"user_tz":-120,"elapsed":3975,"user":{"displayName":"Mirko Di Maggio","userId":"13413056271228513717"}}},"outputs":[],"source":["from importlib.util import spec_from_file_location, module_from_spec\n","\n","spec = spec_from_file_location(\"training_utils\", str(PROJECT_ROOT / \"src/utils/training_utils.py\"))\n","training_utils = module_from_spec(spec)\n","spec.loader.exec_module(training_utils)\n","sys.modules[\"utils.training_utils\"] = training_utils\n","\n","from utils.training_utils import TRAINER_REGISTRY, load_checkpoint\n","from trainers.extract_features import extract_features\n","\n","trainer_modules = [\n","    \"trainers.simclr\",\n","    \"trainers.moco_v2\",\n","    \"trainers.rotation\",\n","    \"trainers.jigsaw\",\n","    \"trainers.supervised\",\n","    \"trainers.transfer\",\n","]\n","for m in trainer_modules:\n","    if m in sys.modules:\n","        importlib.reload(sys.modules[m])\n","    else:\n","        importlib.import_module(m)\n"]},{"cell_type":"code","execution_count":4,"id":"af011c17","metadata":{"id":"af011c17","executionInfo":{"status":"ok","timestamp":1750513785623,"user_tz":-120,"elapsed":3,"user":{"displayName":"Mirko Di Maggio","userId":"13413056271228513717"}}},"outputs":[],"source":["def majority_vote(preds, keys):\n","    patient_to_preds = defaultdict(list)\n","    for key, pred in zip(keys, preds):\n","        parts = key.split(\"_\")\n","        patient_id = next((p for p in parts if p.startswith(\"HP\")), \"unknown\")\n","        patient_to_preds[patient_id].append(pred)\n","\n","    voted_labels = []\n","    true_labels = []\n","    for patient_id, votes in patient_to_preds.items():\n","        counter = Counter(votes)\n","        majority_label = counter.most_common(1)[0][0]\n","        voted_labels.append(majority_label)\n","    return voted_labels\n"]},{"cell_type":"code","execution_count":5,"id":"31f3e4cf","metadata":{"id":"31f3e4cf","executionInfo":{"status":"ok","timestamp":1750513785653,"user_tz":-120,"elapsed":29,"user":{"displayName":"Mirko Di Maggio","userId":"13413056271228513717"}}},"outputs":[],"source":["def evaluate_selfsupervised(trainer, classifier_path, test_path):\n","    import webdataset as wds\n","    import torchvision.transforms as T\n","    from PIL import Image\n","    from collections import defaultdict, Counter\n","    import torch\n","    import joblib\n","    from sklearn.metrics import classification_report, confusion_matrix\n","\n","    logger.info(\"üß™ Evaluation (Self-Supervised)\")\n","\n","    # Carica classificatore e encoder\n","    model = joblib.load(classifier_path)\n","    clf = model[\"model\"]\n","    le = model[\"label_encoder\"]\n","\n","    def make_test_loader():\n","        ds = (\n","            wds.WebDataset(test_path, shardshuffle=False, handler=wds.warn_and_continue, empty_check=False)\n","            .decode(\"pil\")\n","            .map(lambda sample: {\n","                \"img\": T.ToTensor()(\n","                    next((v for k, v in sample.items() if isinstance(v, Image.Image)), None).convert(\"RGB\")\n","                ),\n","                \"key\": sample[\"__key__\"] + \".\" + next((k for k in sample.keys() if k.endswith(\".jpg\")), \"\")\n","            })\n","        )\n","        return torch.utils.data.DataLoader(\n","            ds,\n","            batch_size=64,\n","            shuffle=False,\n","            num_workers=0,\n","            pin_memory=True\n","        )\n","\n","    # Estrai feature\n","    loader = make_test_loader()\n","    feats = extract_features(trainer.encoder, loader, trainer.device)\n","    X = feats[\"features\"].numpy()\n","    keys = feats[\"keys\"]\n","    print(f\"Keys trovate----->>>> {keys}\")\n","    y_pred = clf.predict(X)\n","\n","    def extract_patient_id(k):\n","        parts = k.split(\"_\")\n","        for part in parts:\n","            if part.startswith(\"HP\") or part.startswith(\"H\"):\n","                return part\n","        return \"UNKNOWN\"\n","\n","    def extract_label_from_key(k):\n","        if k.startswith(\"not_tumor\"):\n","            return \"not_tumor\"\n","        return k.split(\"_\")[0]\n","\n","    # Step 1: Costruisci dizionario paziente ‚Üí label tumorale GT (escludendo not_tumor)\n","    true_patient_labels = {}\n","    all_labels_per_patient = defaultdict(list)\n","\n","    for k in keys:\n","        label = extract_label_from_key(k)\n","        pid = extract_patient_id(k)\n","        all_labels_per_patient[pid].append(label)\n","\n","    for pid, labels in all_labels_per_patient.items():\n","        tumor_labels = [lab for lab in labels if lab != \"not_tumor\"]\n","        if len(set(tumor_labels)) == 1:\n","            true_patient_labels[pid] = tumor_labels[0]\n","        elif len(set(tumor_labels)) > 1:\n","            logger.warning(f\"‚ö†Ô∏è Paziente {pid} ha pi√π classi tumorali: {set(tumor_labels)}. Skippato.\")\n","    print(f\"TRUE LABEL PER PAZIENTE {true_patient_labels}\")\n","\n","    # Step 2: Costruisci predizioni per paziente (escludendo predizioni not_tumor)\n","    preds_per_patient = defaultdict(list)\n","    for k, pred in zip(keys, y_pred):\n","        pid = extract_patient_id(k)\n","        if le.classes_[pred] != \"not_tumor\":\n","            preds_per_patient[pid].append(pred)\n","\n","    # Step 3: Majority voting per pazienti validi\n","    y_true, y_majority, valid_pids = [], [], []\n","    for pid, preds in preds_per_patient.items():\n","        if pid not in true_patient_labels or len(preds) == 0:\n","            continue\n","        gt_label = true_patient_labels[pid]\n","        majority = Counter(preds).most_common(1)[0][0]\n","        y_true.append(le.transform([gt_label])[0])\n","        y_majority.append(majority)\n","        valid_pids.append(pid)\n","\n","\n","\n","\n","    if len(y_true) == 0 or len(y_majority) == 0:\n","        print(\"‚ùå Nessun paziente valutabile: majority voting vuoto o label GT non disponibili.\")\n","        return\n","\n","    print(\"\\nüìä Risultati Majority Voting (paziente-level):\")\n","    print(classification_report(y_true, y_majority, target_names=[c for c in le.classes_ if c != \"not_tumor\"]))\n","    print(\"üìâ Confusion Matrix:\")\n","    print(confusion_matrix(y_true, y_majority))\n","    print(f\"‚úÖ Totale pazienti classificati: {len(y_true)}\")\n","\n","    print(\"\\nüßæ Predizione per paziente:\")\n","    for pid, true_encoded, pred_encoded in zip(valid_pids, y_true, y_majority):\n","        true_label = le.inverse_transform([true_encoded])[0]\n","        pred_label = le.inverse_transform([pred_encoded])[0]\n","        print(f\"‚Ä¢ Paziente {pid}: predetto = {pred_label} | reale = {true_label}\")"]},{"cell_type":"code","source":["def evaluate_supervised(trainer, test_path):\n","    import webdataset as wds\n","    import torchvision.transforms as T\n","    from PIL import Image\n","    from sklearn.metrics import classification_report, confusion_matrix\n","\n","    logger.info(\"üß™ Evaluation (Supervised/Transfer con Majority Voting)\")\n","\n","    def extract_patient_id(k):\n","        parts = k.split(\"_\")\n","        for part in parts:\n","            if part.startswith(\"HP\") or part.startswith(\"H\"):\n","                return part\n","        return \"UNKNOWN\"\n","\n","    def extract_label_from_key(k):\n","        if k.startswith(\"not_tumor\"):\n","            return \"not_tumor\"\n","        return k.split(\"_\")[0]\n","\n","    def make_test_loader():\n","        ds = (\n","            wds.WebDataset(test_path, shardshuffle=False, handler=wds.warn_and_continue, empty_check=False)\n","            .decode(\"pil\")\n","            .map(lambda sample: {\n","                \"img\": T.ToTensor()(\n","                    next((v for k, v in sample.items() if isinstance(v, Image.Image)), None).convert(\"RGB\")\n","                ),\n","                \"key\": sample[\"__key__\"] + \".\" + next((k for k in sample.keys() if k.endswith(\".jpg\")), \"\")\n","            })\n","        )\n","        return torch.utils.data.DataLoader(ds, batch_size=64, shuffle=False, num_workers=0, pin_memory=True)\n","\n","    # Step 1: Estrai feature e predizioni\n","    loader = make_test_loader()\n","    model = trainer.model.to(trainer.device)\n","    model.eval()\n","    le = trainer.label_encoder\n","\n","    y_pred, keys = [], []\n","\n","    with torch.no_grad():\n","        for batch in loader:\n","            imgs = batch[\"img\"].to(trainer.device)\n","            logits = model(imgs)\n","            preds = torch.argmax(logits, dim=1).cpu().numpy()\n","            y_pred.extend(preds)\n","            keys.extend(batch[\"key\"])\n","\n","    # Step 2: Costruisci mappa paziente ‚Üí label GT tumorale\n","    true_patient_labels = {}\n","    all_labels_per_patient = defaultdict(list)\n","    for k in keys:\n","        label = extract_label_from_key(k)\n","        pid = extract_patient_id(k)\n","        all_labels_per_patient[pid].append(label)\n","\n","    for pid, labels in all_labels_per_patient.items():\n","        tumor_labels = [lab for lab in labels if lab != \"not_tumor\"]\n","        if len(set(tumor_labels)) == 1:\n","            true_patient_labels[pid] = tumor_labels[0]\n","        elif len(set(tumor_labels)) > 1:\n","            logger.warning(f\"‚ö†Ô∏è Paziente {pid} ha pi√π classi tumorali: {set(tumor_labels)}. Skippato.\")\n","    print(f\"TRUE LABEL PER PAZIENTE {true_patient_labels}\")\n","\n","    # Step 3: Raggruppa predizioni per paziente (escludi not_tumor)\n","    preds_per_patient = defaultdict(list)\n","    for k, pred in zip(keys, y_pred):\n","        pid = extract_patient_id(k)\n","        if le.classes_[pred] != \"not_tumor\":\n","            preds_per_patient[pid].append(pred)\n","\n","    # Step 4: Majority voting\n","    y_true, y_majority, valid_pids = [], [], []\n","    for pid, preds in preds_per_patient.items():\n","        if pid not in true_patient_labels or len(preds) == 0:\n","            continue\n","        gt_label = true_patient_labels[pid]\n","        majority = Counter(preds).most_common(1)[0][0]\n","        y_true.append(le.transform([gt_label])[0])\n","        y_majority.append(majority)\n","        valid_pids.append(pid)\n","\n","    if len(y_true) == 0 or len(y_majority) == 0:\n","        print(\"‚ùå Nessun paziente valutabile.\")\n","        return\n","\n","    print(\"\\nüìä Risultati Majority Voting (paziente-level):\")\n","    print(classification_report(y_true, y_majority, target_names=[c for c in le.classes_ if c != \"not_tumor\"]))\n","    print(\"üìâ Confusion Matrix:\")\n","    print(confusion_matrix(y_true, y_majority))\n","    print(f\"‚úÖ Totale pazienti classificati: {len(y_true)}\")\n","\n","    print(\"\\nüßæ Predizione per paziente:\")\n","    for pid, true_encoded, pred_encoded in zip(valid_pids, y_true, y_majority):\n","        true_label = le.inverse_transform([true_encoded])[0]\n","        pred_label = le.inverse_transform([pred_encoded])[0]\n","        print(f\"‚Ä¢ Paziente {pid}: predetto = {pred_label} | reale = {true_label}\")\n"],"metadata":{"id":"LiESv8V7Xx03","executionInfo":{"status":"ok","timestamp":1750513785669,"user_tz":-120,"elapsed":13,"user":{"displayName":"Mirko Di Maggio","userId":"13413056271228513717"}}},"id":"LiESv8V7Xx03","execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"id":"0ba00a43","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ba00a43","executionInfo":{"status":"ok","timestamp":1750513799010,"user_tz":-120,"elapsed":13338,"user":{"displayName":"Mirko Di Maggio","userId":"13413056271228513717"}},"outputId":"92e50e07-4082-4b40-f523-9203388f28d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìä Patch totali trovate da count_samples: 1500\n","üì¶ Batch totali calcolati: 47\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["TRUE LABEL PER PAZIENTE {'HP20002450': 'ONCO', 'HP18014084': 'CHROMO', 'HP12.7726': 'pRCC', 'HP11.12318': 'ccRCC', 'HP19.1277': 'pRCC', 'HP19.4075': 'ccRCC', 'HP18.5818': 'pRCC', 'HP14.4279': 'pRCC', 'HP12.13588': 'ccRCC', 'HP18.13618': 'pRCC', 'HP12.6073': 'ccRCC', 'HP19.8394': 'ccRCC', 'HP19.10064': 'ccRCC', 'HP02.10180': 'ccRCC', 'HP12.6691': 'ccRCC', 'HP12.8355': 'ccRCC', 'HP19.7421': 'ccRCC', 'HP15.12550': 'ccRCC'}\n","\n","üìä Risultati Majority Voting (paziente-level):\n","              precision    recall  f1-score   support\n","\n","      CHROMO       0.00      0.00      0.00         1\n","        ONCO       0.50      1.00      0.67         1\n","       ccRCC       1.00      0.36      0.53        11\n","        pRCC       0.42      1.00      0.59         5\n","\n","    accuracy                           0.56        18\n","   macro avg       0.48      0.59      0.45        18\n","weighted avg       0.75      0.56      0.53        18\n","\n","üìâ Confusion Matrix:\n","[[0 1 0 0]\n"," [0 1 0 0]\n"," [0 0 4 7]\n"," [0 0 0 5]]\n","‚úÖ Totale pazienti classificati: 18\n","\n","üßæ Predizione per paziente:\n","‚Ä¢ Paziente HP20002450: predetto = ONCO | reale = ONCO\n","‚Ä¢ Paziente HP18014084: predetto = ONCO | reale = CHROMO\n","‚Ä¢ Paziente HP12.7726: predetto = pRCC | reale = pRCC\n","‚Ä¢ Paziente HP11.12318: predetto = pRCC | reale = ccRCC\n","‚Ä¢ Paziente HP19.1277: predetto = pRCC | reale = pRCC\n","‚Ä¢ Paziente HP19.4075: predetto = ccRCC | reale = ccRCC\n","‚Ä¢ Paziente HP18.5818: predetto = pRCC | reale = pRCC\n","‚Ä¢ Paziente HP14.4279: predetto = pRCC | reale = pRCC\n","‚Ä¢ Paziente HP12.13588: predetto = pRCC | reale = ccRCC\n","‚Ä¢ Paziente HP12.6073: predetto = pRCC | reale = ccRCC\n","‚Ä¢ Paziente HP19.8394: predetto = ccRCC | reale = ccRCC\n","‚Ä¢ Paziente HP19.10064: predetto = ccRCC | reale = ccRCC\n","‚Ä¢ Paziente HP02.10180: predetto = pRCC | reale = ccRCC\n","‚Ä¢ Paziente HP12.6691: predetto = pRCC | reale = ccRCC\n","‚Ä¢ Paziente HP18.13618: predetto = pRCC | reale = pRCC\n","‚Ä¢ Paziente HP12.8355: predetto = pRCC | reale = ccRCC\n","‚Ä¢ Paziente HP19.7421: predetto = ccRCC | reale = ccRCC\n","‚Ä¢ Paziente HP15.12550: predetto = pRCC | reale = ccRCC\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n","/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]}],"source":["from sklearn.metrics import classification_report, confusion_matrix\n","\n","run_model = cfg.get(\"run_model\", \"all\").lower()\n","models_cfg = cfg[\"models\"]\n","tasks = list(models_cfg.items()) if run_model == \"all\" else [(run_model, models_cfg[run_model])]\n","\n","for name, m_cfg in tasks:\n","    if name not in TRAINER_REGISTRY:\n","        raise KeyError(f\"‚ùå Trainer '{name}' non trovato\")\n","\n","    trainer = TRAINER_REGISTRY[name](m_cfg, cfg[\"data\"])\n","    test_path = str(cfg[\"data\"][\"test\"])\n","    ckpt = PROJECT_ROOT / \"data/processed/webdataset_2500/train/checkpoints\" / f\"{trainer.__class__.__name__}_best.pt\"\n","\n","    if name in [\"supervised\", \"transfer\"]:\n","        # üîê Carica modello completo per supervised/transfer\n","        load_checkpoint(ckpt, model=trainer.model)\n","        trainer.model = trainer.model.to(trainer.device)\n","\n","        # üîç Evaluation diretta con majority voting\n","        evaluate_supervised(trainer, test_path)\n","    else:\n","        # üß† Per modelli self-supervised: encoder + projector + classificatore esterno\n","        classifier_path = PROJECT_ROOT / f\"classifier/{name}_classifier.joblib\"\n","        if not classifier_path.exists():\n","            logger.warning(f\"‚ö†Ô∏è Classificatore non trovato per '{name}', skipping.\")\n","            continue\n","\n","        model = torch.nn.Sequential(trainer.encoder, trainer.projector)\n","        load_checkpoint(ckpt, model=model)\n","        trainer.encoder = model[0].to(trainer.device)\n","        trainer.projector = model[1].to(trainer.device)\n","\n","        evaluate_selfsupervised(trainer, classifier_path, test_path)\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}